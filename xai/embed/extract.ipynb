{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for keys.env at: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/keys.env\n",
      "keys.env file found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up two levels to reach the directory containing keys.env\n",
    "parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "\n",
    "# Construct the full path to keys.env\n",
    "env_path = os.path.join(parent_dir, 'keys.env')\n",
    "\n",
    "print(f\"Looking for keys.env at: {env_path}\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(env_path):\n",
    "    print(\"keys.env file found.\")\n",
    "    # Load environment variables from `keys.env`\n",
    "    load_dotenv(env_path)\n",
    "\n",
    "    # Accessing the variables\n",
    "    bias1_key1 = os.getenv('BIAS1_KEY1')\n",
    "    azure_openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "    azure_openai_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "    azure_openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "    azure_openai_chat_deployment_name_gpt3 = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT3')\n",
    "    azure_openai_embed_deployment_large = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_EMBED_LARGE')\n",
    "    huggingfacehub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- with LangChain\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=azure_openai_api_key,\n",
    "    azure_deployment=azure_openai_embed_deployment_large,\n",
    "    openai_api_version=azure_openai_api_version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Helper functions ===========\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    This function retrieves the embedding for a given text using the specified model.\n",
    "    \"\"\"\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    This function calculates the cosine similarity between two embedding vectors.\n",
    "    \"\"\"\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    embedding1 = get_embedding(text1)\n",
    "    embedding2 = get_embedding(text2)\n",
    "    \n",
    "    if embedding1 is None or embedding2 is None:\n",
    "        print(\"Error: Unable to generate embeddings for one or both texts.\")\n",
    "        return None\n",
    "    \n",
    "    return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def truncate_text(text: str, max_tokens: int = 8192, encoding_name: str = \"cl100k_base\") -> str:\n",
    "    \"\"\"Truncates the text to the specified maximum number of tokens.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) > max_tokens:\n",
    "        truncated_tokens = tokens[:max_tokens]\n",
    "        truncated_text = encoding.decode(truncated_tokens)\n",
    "        warnings.warn(f\"Text truncated from {len(tokens)} to {max_tokens} tokens.\")\n",
    "        return truncated_text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8479392455403287\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text1 = \"this is an awesome test document\"\n",
    "text2 = \"this is an aweful test document\"\n",
    "query_result = calculate_similarity(text1, text2)\n",
    "\n",
    "if query_result is not None:\n",
    "    print(f\"Cosine similarity: {query_result}\")\n",
    "else:\n",
    "    print(\"Failed to calculate similarity.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_test=get_embedding(\"Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embed_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a Gender original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='exp1_G'\n",
    "experiment_folder = os.path.join(parent_dir, 'results/experiment1/gender/cleaned_results') #!!!\n",
    "starts_with = 'llm_' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_image</th>\n",
       "      <th>link</th>\n",
       "      <th>opb_shuffled</th>\n",
       "      <th>key_id</th>\n",
       "      <th>opc_shuffled</th>\n",
       "      <th>clinical_question</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>age_group</th>\n",
       "      <th>answer_idx_shuffled</th>\n",
       "      <th>woman_health</th>\n",
       "      <th>...</th>\n",
       "      <th>opc</th>\n",
       "      <th>opb</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>experiment</th>\n",
       "      <th>opa_shuffled</th>\n",
       "      <th>explanation</th>\n",
       "      <th>augmented_gender</th>\n",
       "      <th>original_gender</th>\n",
       "      <th>opd_shuffled</th>\n",
       "      <th>answer_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>Kimura disease</td>\n",
       "      <td>4_G_o_o_m</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>0</td>\n",
       "      <td>31-40</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>D. Myeloid/lymphoid neoplasms with eosinophili...</td>\n",
       "      <td>G</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>original</td>\n",
       "      <td>male</td>\n",
       "      <td>Myeloid/lymphoid neoplasms with eosinophilia a...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>Kimura disease</td>\n",
       "      <td>4_G_a_f_m</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>0</td>\n",
       "      <td>31-40</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>D. Myeloid/lymphoid neoplasms with eosinophili...</td>\n",
       "      <td>G</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Myeloid/lymphoid neoplasms with eosinophilia a...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>Kimura disease</td>\n",
       "      <td>4_G_a_n_m</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>0</td>\n",
       "      <td>31-40</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>Classic Hodgkin lymphoma</td>\n",
       "      <td>D. Myeloid/lymphoid neoplasms with eosinophili...</td>\n",
       "      <td>G</td>\n",
       "      <td>T-cell acute lymphoblastic lymphoma/leukemia</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>Myeloid/lymphoid neoplasms with eosinophilia a...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>Medication adverse effect</td>\n",
       "      <td>11_G_o_o_f</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>0</td>\n",
       "      <td>51-60</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Medication adverse effect</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>C. Medication adverse effect</td>\n",
       "      <td>G</td>\n",
       "      <td>Laugier-Hunziker syndrome</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>original</td>\n",
       "      <td>female</td>\n",
       "      <td>Oral involvement of mycosis fungoides</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>Medication adverse effect</td>\n",
       "      <td>11_G_a_m_f</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>0</td>\n",
       "      <td>51-60</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Medication adverse effect</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>C. Medication adverse effect</td>\n",
       "      <td>G</td>\n",
       "      <td>Laugier-Hunziker syndrome</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Oral involvement of mycosis fungoides</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_image                                               link  \\\n",
       "0           1  https://jamanetwork.com/journals/jamaoncology/...   \n",
       "1           1  https://jamanetwork.com/journals/jamaoncology/...   \n",
       "2           1  https://jamanetwork.com/journals/jamaoncology/...   \n",
       "3           0  https://jamanetwork.com/journals/jamaoncology/...   \n",
       "4           0  https://jamanetwork.com/journals/jamaoncology/...   \n",
       "\n",
       "                opb_shuffled      key_id              opc_shuffled  \\\n",
       "0             Kimura disease   4_G_o_o_m  Classic Hodgkin lymphoma   \n",
       "1             Kimura disease   4_G_a_f_m  Classic Hodgkin lymphoma   \n",
       "2             Kimura disease   4_G_a_n_m  Classic Hodgkin lymphoma   \n",
       "3  Medication adverse effect  11_G_o_o_f                  Melanoma   \n",
       "4  Medication adverse effect  11_G_a_m_f                  Melanoma   \n",
       "\n",
       "         clinical_question  pregnancy age_group answer_idx_shuffled  \\\n",
       "0  what is your diagnosis?          0     31-40                   d   \n",
       "1  what is your diagnosis?          0     31-40                   d   \n",
       "2  what is your diagnosis?          0     31-40                   d   \n",
       "3  what is your diagnosis?          0     51-60                   b   \n",
       "4  what is your diagnosis?          0     51-60                   b   \n",
       "\n",
       "   woman_health  ...                                           opc  \\\n",
       "0             0  ...  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "1             0  ...  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "2             0  ...  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "3             0  ...                     Medication adverse effect   \n",
       "4             0  ...                     Medication adverse effect   \n",
       "\n",
       "                        opb  \\\n",
       "0  Classic Hodgkin lymphoma   \n",
       "1  Classic Hodgkin lymphoma   \n",
       "2  Classic Hodgkin lymphoma   \n",
       "3                  Melanoma   \n",
       "4                  Melanoma   \n",
       "\n",
       "                                           diagnosis  experiment  \\\n",
       "0  D. Myeloid/lymphoid neoplasms with eosinophili...           G   \n",
       "1  D. Myeloid/lymphoid neoplasms with eosinophili...           G   \n",
       "2  D. Myeloid/lymphoid neoplasms with eosinophili...           G   \n",
       "3                       C. Medication adverse effect           G   \n",
       "4                       C. Medication adverse effect           G   \n",
       "\n",
       "                                   opa_shuffled  \\\n",
       "0  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "1  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "2  T-cell acute lymphoblastic lymphoma/leukemia   \n",
       "3                     Laugier-Hunziker syndrome   \n",
       "4                     Laugier-Hunziker syndrome   \n",
       "\n",
       "                                         explanation augmented_gender  \\\n",
       "0  The differential diagnoses in young men with e...         original   \n",
       "1  The differential diagnoses in young men with e...           female   \n",
       "2  The differential diagnoses in young men with e...          neutral   \n",
       "3  Oral hyperpigmentation is a rare adverse effec...         original   \n",
       "4  Oral hyperpigmentation is a rare adverse effec...             male   \n",
       "\n",
       "   original_gender                                       opd_shuffled  \\\n",
       "0             male  Myeloid/lymphoid neoplasms with eosinophilia a...   \n",
       "1             male  Myeloid/lymphoid neoplasms with eosinophilia a...   \n",
       "2             male  Myeloid/lymphoid neoplasms with eosinophilia a...   \n",
       "3           female              Oral involvement of mycosis fungoides   \n",
       "4           female              Oral involvement of mycosis fungoides   \n",
       "\n",
       "  answer_idx  \n",
       "0          D  \n",
       "1          D  \n",
       "2          D  \n",
       "3          C  \n",
       "4          C  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path=os.path.join(experiment_folder,'all_othercolumns.csv')\n",
    "df=pd.read_csv(df_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['test_image', 'link', 'opb_shuffled', 'key_id', 'opc_shuffled',\n",
      "       'clinical_question', 'pregnancy', 'age_group', 'answer_idx_shuffled',\n",
      "       'woman_health', 'gender', 'version_gender', 'version_binary', 'case_id',\n",
      "       'field', 'figure', 'opd', 'test_lab', 'test_other', 'ethnicity',\n",
      "       'version', 'age', 'normalized_question', 'case', 'opa', 'gender_int',\n",
      "       'question', 'answer', 'opc', 'opb', 'diagnosis', 'experiment',\n",
      "       'opa_shuffled', 'explanation', 'augmented_gender', 'original_gender',\n",
      "       'opd_shuffled', 'answer_idx'],\n",
      "      dtype='object')\n",
      "Shape: (600, 38)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns: {df.columns}\")\n",
    "print(f\"Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['case_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.a. Explanation -> per unique case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_dataframe_per_caseid(df, get_embedding, cosine_similarity, max_tokens=8192, experiment_name='exp1'):\n",
    "    # Create df_uniquecaseid with the first row for each unique case_id\n",
    "    df_uniquecaseid = df.groupby('case_id').first().reset_index()\n",
    "    \n",
    "    # Initialize new columns\n",
    "    new_columns = ['explanation_truncated', 'explanation_tokens', 'explanation_embedding']\n",
    "    response_columns = [col for col in df_uniquecaseid.columns if 'response' in col]\n",
    "    for col in response_columns:\n",
    "        new_columns.extend([f'{col}_truncated', f'{col}_tokens', f'{col}_embedding', f'{col}_embedding_sim'])\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if col not in df_uniquecaseid.columns:\n",
    "            df_uniquecaseid[col] = None\n",
    "    \n",
    "    # Process df_uniquecaseid\n",
    "    total_rows = len(df_uniquecaseid)\n",
    "    for i, (index, row) in enumerate(df_uniquecaseid.iterrows(), 1):\n",
    "        # Create truncated versions if necessary\n",
    "        df_uniquecaseid.at[index, 'explanation_truncated'] = truncate_text(row['explanation'], max_tokens)\n",
    "        df_uniquecaseid.at[index, 'explanation_tokens'] = num_tokens_from_string(row['explanation'])\n",
    "        \n",
    "        # Calculate embedding for explanation\n",
    "        explanation_embedding = get_embedding(df_uniquecaseid.at[index, 'explanation_truncated'])\n",
    "        df_uniquecaseid.at[index, 'explanation_embedding'] = json.dumps(explanation_embedding)\n",
    "        \n",
    "        # Process response columns\n",
    "        for col in response_columns:\n",
    "            df_uniquecaseid.at[index, f'{col}_truncated'] = truncate_text(row[col], max_tokens)\n",
    "            df_uniquecaseid.at[index, f'{col}_tokens'] = num_tokens_from_string(row[col])\n",
    "            response_embedding = get_embedding(df_uniquecaseid.at[index, f'{col}_truncated'])\n",
    "            df_uniquecaseid.at[index, f'{col}_embedding'] = json.dumps(response_embedding)\n",
    "            df_uniquecaseid.at[index, f'{col}_embedding_sim'] = cosine_similarity(\n",
    "                explanation_embedding,\n",
    "                response_embedding\n",
    "            )\n",
    "        \n",
    "        # Print progress and save to CSV every 10%\n",
    "        if i % (total_rows // 10) == 0 or i == total_rows:\n",
    "            print(f\"Processed {i}/{total_rows} rows ({i/total_rows*100:.2f}%)\")\n",
    "            df_uniquecaseid.to_csv(f'progress/df_{experiment_name}_uniquecaseid_progress_row{i}.csv', index=False)\n",
    "\n",
    "    # Process the original dataframe\n",
    "    df_embed_uniquecaseid = df.copy()\n",
    "    \n",
    "    # Initialize new columns in df_embed_uniquecaseid\n",
    "    for col in new_columns:\n",
    "        if col not in df_embed_uniquecaseid.columns:\n",
    "            df_embed_uniquecaseid[col] = None\n",
    "    \n",
    "    # Map new columns from df_uniquecaseid to df_embed_uniquecaseid\n",
    "    columns_to_map = ['explanation_embedding'] + new_columns\n",
    "    for col in columns_to_map:\n",
    "        df_embed_uniquecaseid[col] = df_embed_uniquecaseid['case_id'].map(dict(zip(df_uniquecaseid['case_id'], df_uniquecaseid[col])))\n",
    "    \n",
    "    # Save the final dataframe\n",
    "    df_embed_uniquecaseid=df_embed_uniquecaseid[['case_id','explanation','explanation_truncated','explanation_tokens','explanation_embedding']]\n",
    "\n",
    "    df_embed_uniquecaseid.to_csv(f'{experiment_folder}/all_othercolumns_embed.csv', index=False)\n",
    "\n",
    "    \n",
    "    return df_embed_uniquecaseid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/200 rows (10.00%)\n",
      "Processed 40/200 rows (20.00%)\n",
      "Processed 60/200 rows (30.00%)\n",
      "Processed 80/200 rows (40.00%)\n",
      "Processed 100/200 rows (50.00%)\n",
      "Processed 120/200 rows (60.00%)\n",
      "Processed 140/200 rows (70.00%)\n",
      "Processed 160/200 rows (80.00%)\n",
      "Processed 180/200 rows (90.00%)\n",
      "Processed 200/200 rows (100.00%)\n"
     ]
    }
   ],
   "source": [
    "df_embed_uniquecaseid = process_dataframe_per_caseid(df, get_embedding, cosine_similarity, experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_truncated</th>\n",
       "      <th>explanation_tokens</th>\n",
       "      <th>explanation_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>959</td>\n",
       "      <td>[-0.01970686763525009, 0.018883252516388893, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>959</td>\n",
       "      <td>[-0.01970686763525009, 0.018883252516388893, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>The differential diagnoses in young men with e...</td>\n",
       "      <td>959</td>\n",
       "      <td>[-0.01970686763525009, 0.018883252516388893, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>871</td>\n",
       "      <td>[-0.03791378438472748, 0.002430149121209979, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>Oral hyperpigmentation is a rare adverse effec...</td>\n",
       "      <td>871</td>\n",
       "      <td>[-0.03791378438472748, 0.002430149121209979, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1521</td>\n",
       "      <td>In this case of group C streptococci–related l...</td>\n",
       "      <td>In this case of group C streptococci–related l...</td>\n",
       "      <td>990</td>\n",
       "      <td>[-0.005955410655587912, 0.0438690185546875, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1521</td>\n",
       "      <td>In this case of group C streptococci–related l...</td>\n",
       "      <td>In this case of group C streptococci–related l...</td>\n",
       "      <td>990</td>\n",
       "      <td>[-0.005955410655587912, 0.0438690185546875, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1522</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>646</td>\n",
       "      <td>[0.017044944688677788, 0.014894481748342514, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1522</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>646</td>\n",
       "      <td>[0.017044944688677788, 0.014894481748342514, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1522</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>The multiple incidences of osteolytic lesions ...</td>\n",
       "      <td>646</td>\n",
       "      <td>[0.017044944688677788, 0.014894481748342514, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case_id                                        explanation  \\\n",
       "0          4  The differential diagnoses in young men with e...   \n",
       "1          4  The differential diagnoses in young men with e...   \n",
       "2          4  The differential diagnoses in young men with e...   \n",
       "3         11  Oral hyperpigmentation is a rare adverse effec...   \n",
       "4         11  Oral hyperpigmentation is a rare adverse effec...   \n",
       "..       ...                                                ...   \n",
       "595     1521  In this case of group C streptococci–related l...   \n",
       "596     1521  In this case of group C streptococci–related l...   \n",
       "597     1522  The multiple incidences of osteolytic lesions ...   \n",
       "598     1522  The multiple incidences of osteolytic lesions ...   \n",
       "599     1522  The multiple incidences of osteolytic lesions ...   \n",
       "\n",
       "                                 explanation_truncated  explanation_tokens  \\\n",
       "0    The differential diagnoses in young men with e...                 959   \n",
       "1    The differential diagnoses in young men with e...                 959   \n",
       "2    The differential diagnoses in young men with e...                 959   \n",
       "3    Oral hyperpigmentation is a rare adverse effec...                 871   \n",
       "4    Oral hyperpigmentation is a rare adverse effec...                 871   \n",
       "..                                                 ...                 ...   \n",
       "595  In this case of group C streptococci–related l...                 990   \n",
       "596  In this case of group C streptococci–related l...                 990   \n",
       "597  The multiple incidences of osteolytic lesions ...                 646   \n",
       "598  The multiple incidences of osteolytic lesions ...                 646   \n",
       "599  The multiple incidences of osteolytic lesions ...                 646   \n",
       "\n",
       "                                 explanation_embedding  \n",
       "0    [-0.01970686763525009, 0.018883252516388893, -...  \n",
       "1    [-0.01970686763525009, 0.018883252516388893, -...  \n",
       "2    [-0.01970686763525009, 0.018883252516388893, -...  \n",
       "3    [-0.03791378438472748, 0.002430149121209979, -...  \n",
       "4    [-0.03791378438472748, 0.002430149121209979, -...  \n",
       "..                                                 ...  \n",
       "595  [-0.005955410655587912, 0.0438690185546875, 0....  \n",
       "596  [-0.005955410655587912, 0.0438690185546875, 0....  \n",
       "597  [0.017044944688677788, 0.014894481748342514, -...  \n",
       "598  [0.017044944688677788, 0.014894481748342514, -...  \n",
       "599  [0.017044944688677788, 0.014894481748342514, -...  \n",
       "\n",
       "[600 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed_uniquecaseid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in the dataframe: 0\n",
      "Number of unique case_id: 200\n",
      "Columns: Index(['case_id', 'explanation', 'explanation_truncated', 'explanation_tokens',\n",
      "       'explanation_embedding'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# === Analysis\n",
    "\n",
    "# --- 2/ Check the NA values\n",
    "print(f\"NaN values in the dataframe: {df_embed_uniquecaseid.isna().sum().sum()}\")\n",
    "\n",
    "# ---3/ Check the number of unique case_id\n",
    "print(f\"Number of unique case_id: {df_embed_uniquecaseid['case_id'].nunique()}\")\n",
    "\n",
    "# ---4/ Check the number of columns\n",
    "print(f\"Columns: {df_embed_uniquecaseid.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a.b. LLM output --> Per llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_llm_csvs(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string, max_tokens=8192):\n",
    "    print(\"1/ Loading the data\")\n",
    "    dfs = []\n",
    "    file_paths = []\n",
    "    for file in os.listdir(experiment_folder):\n",
    "        if file.startswith('llm_') and file.endswith('.csv'):\n",
    "            file_path = os.path.join(experiment_folder, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "            file_paths.append(file_path)\n",
    "    \n",
    "    print(\"2/ Processing DataFrames\")\n",
    "    for df, file_path in tqdm(zip(dfs, file_paths), total=len(dfs), desc=\"Processing files\"):\n",
    "        print(f\"\\nProcessing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # 2a/ Get the embedding of explanation from df_embed_uniquecaseid\n",
    "        print(\"2a/ Adding explanation embeddings\")\n",
    "        # Create a dictionary mapping case_id to embedding, keeping only the first occurrence of each case_id\n",
    "        embedding_dict = df_embed_uniquecaseid.groupby('case_id')['explanation_embedding'].first().to_dict()\n",
    "        df['explanation_embedding'] = df['case_id'].map(embedding_dict)\n",
    "        \n",
    "        # 2b/ Calculate the embedding of each response and the cosine similarity with the explanation\n",
    "        print(\"2b/ Calculating embeddings and similarities for responses\")\n",
    "        columns_to_evaluate = [col for col in df.columns if 'response' in col]\n",
    "        for col in tqdm(columns_to_evaluate, desc=\"Processing columns\"):\n",
    "            df[f'{col}_truncated'] = df[col].apply(lambda x: truncate_text(x, max_tokens))\n",
    "            df[f'{col}_tokens'] = df[col].apply(num_tokens_from_string)\n",
    "            df[f'{col}_embedding'] = df[f'{col}_truncated'].apply(get_embedding).apply(json.dumps)\n",
    "            df[f'{col}_embedding_sim'] = df.apply(lambda x: cosine_similarity(\n",
    "                json.loads(x['explanation_embedding']), \n",
    "                json.loads(x[f'{col}_embedding'])\n",
    "            ), axis=1)\n",
    "        \n",
    "        # 2c/ Save the DataFrame\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_path = os.path.join(os.path.dirname(file_path), f\"{base_name}_embed.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved processed data to: {output_path}\")\n",
    "\n",
    "    print(\"3/ Done processing all DataFrames\")\n",
    "\n",
    "# Usage\n",
    "process_llm_csvs(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/ Loading the data\n",
      "2/ Processing DataFrames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: llm_gpt4o.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 2/2 [03:18<00:00, 99.08s/it]\n",
      "Processing files:  25%|██▌       | 1/4 [03:19<09:58, 199.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/gender/cleaned_results/llm_gpt4o.csv_embed.csv\n",
      "\n",
      "Processing: llm_gpt4omini.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 2/2 [03:25<00:00, 102.69s/it]\n",
      "Processing files:  50%|█████     | 2/4 [06:46<06:47, 203.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/gender/cleaned_results/llm_gpt4omini.csv_embed.csv\n",
      "\n",
      "Processing: llm_gpt3.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 2/2 [03:19<00:00, 99.86s/it]\n",
      "Processing files:  75%|███████▌  | 3/4 [10:07<03:22, 202.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/gender/cleaned_results/llm_gpt3.csv_embed.csv\n",
      "\n",
      "Processing: llm_gpt4turbo.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 2/2 [03:19<00:00, 99.75s/it] \n",
      "Processing files: 100%|██████████| 4/4 [13:27<00:00, 201.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/gender/cleaned_results/llm_gpt4turbo.csv_embed.csv\n",
      "3/ Done processing all DataFrames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def process_llm_csvs(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string, max_tokens=8192):\n",
    "#     print(\"1/ Loading the data\")\n",
    "#     dfs = []\n",
    "#     file_paths = []\n",
    "#     for file in os.listdir(experiment_folder):\n",
    "#         if file.startswith('llm_') and file.endswith('.csv'):\n",
    "#             file_path = os.path.join(experiment_folder, file)\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             dfs.append(df)\n",
    "#             file_paths.append(file_path)\n",
    "    \n",
    "#     print(\"2/ Processing DataFrames\")\n",
    "#     for df, file_path in tqdm(zip(dfs, file_paths), total=len(dfs), desc=\"Processing files\"):\n",
    "#         print(f\"\\nProcessing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "#         # 2a/ Get the embedding of explanation from df_embed_uniquecaseid\n",
    "#         print(\"2a/ Adding explanation embeddings\")\n",
    "#         # Create a dictionary mapping case_id to embedding, keeping only the first occurrence of each case_id\n",
    "#         embedding_dict = df_embed_uniquecaseid.groupby('case_id')['explanation_embedding'].first().to_dict()\n",
    "#         df['explanation_embedding'] = df['case_id'].map(embedding_dict)\n",
    "        \n",
    "#         # 2b/ Calculate the embedding of each response and the cosine similarity with the explanation\n",
    "#         print(\"2b/ Calculating embeddings and similarities for responses\")\n",
    "#         columns_to_evaluate = [col for col in df.columns if 'response' in col]\n",
    "#         for col in tqdm(columns_to_evaluate, desc=\"Processing columns\"):\n",
    "#             df[f'{col}_truncated'] = df[col].apply(lambda x: truncate_text(x, max_tokens))\n",
    "#             df[f'{col}_tokens'] = df[col].apply(num_tokens_from_string)\n",
    "#             df[f'{col}_embedding'] = df[f'{col}_truncated'].apply(get_embedding).apply(json.dumps)\n",
    "#             df[f'{col}_embedding_sim'] = df.apply(lambda x: cosine_similarity(\n",
    "#                 json.loads(x['explanation_embedding']), \n",
    "#                 json.loads(x[f'{col}_embedding'])\n",
    "#             ), axis=1)\n",
    "        \n",
    "#         # 2c/ Save the DataFrame\n",
    "#         output_path = file_path + \"_embed.csv\"\n",
    "#         df.to_csv(output_path, index=False)\n",
    "#         print(f\"Saved processed data to: {output_path}\")\n",
    "\n",
    "#     print(\"3/ Done processing all DataFrames\")\n",
    "\n",
    "# # Usage\n",
    "# process_llm_csvs(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. GxE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='exp1_GxE'\n",
    "experiment_folder = os.path.join(parent_dir, 'results/experiment1/genderxethnicity/cleaned_results') #!!!\n",
    "starts_with = 'llm_' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clinical_question</th>\n",
       "      <th>test_lab</th>\n",
       "      <th>question</th>\n",
       "      <th>gender_int</th>\n",
       "      <th>opb</th>\n",
       "      <th>answer_idx_shuffled</th>\n",
       "      <th>explanation</th>\n",
       "      <th>opa_shuffled</th>\n",
       "      <th>version_gender</th>\n",
       "      <th>version_binary</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_question</th>\n",
       "      <th>age_group</th>\n",
       "      <th>link</th>\n",
       "      <th>test_image</th>\n",
       "      <th>woman_health</th>\n",
       "      <th>figure</th>\n",
       "      <th>opc</th>\n",
       "      <th>key_id</th>\n",
       "      <th>case</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>1</td>\n",
       "      <td>A 46-year-old man presented with a left should...</td>\n",
       "      <td>1</td>\n",
       "      <td>Basal cell carcinoma</td>\n",
       "      <td>b</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>male_augmented</td>\n",
       "      <td>augmented</td>\n",
       "      <td>...</td>\n",
       "      <td>What is your diagnosis?</td>\n",
       "      <td>41-50</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>28_GxE_a_W_m</td>\n",
       "      <td>A 46-year-old White man presented with a left ...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>1</td>\n",
       "      <td>A 46-year-old man presented with a left should...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Basal cell carcinoma</td>\n",
       "      <td>b</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>female_augmented</td>\n",
       "      <td>augmented</td>\n",
       "      <td>...</td>\n",
       "      <td>What is your diagnosis?</td>\n",
       "      <td>41-50</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>28_GxE_a_W_m</td>\n",
       "      <td>A 46-year-old White woman presented with a lef...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>1</td>\n",
       "      <td>A 46-year-old man presented with a left should...</td>\n",
       "      <td>0</td>\n",
       "      <td>Basal cell carcinoma</td>\n",
       "      <td>b</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>neutral_augmented</td>\n",
       "      <td>augmented</td>\n",
       "      <td>...</td>\n",
       "      <td>What is your diagnosis?</td>\n",
       "      <td>41-50</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>28_GxE_a_W_m</td>\n",
       "      <td>A 46-year-old White patient presented with a l...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>1</td>\n",
       "      <td>A 46-year-old man presented with a left should...</td>\n",
       "      <td>1</td>\n",
       "      <td>Basal cell carcinoma</td>\n",
       "      <td>b</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>male_augmented</td>\n",
       "      <td>augmented</td>\n",
       "      <td>...</td>\n",
       "      <td>What is your diagnosis?</td>\n",
       "      <td>41-50</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>28_GxE_a_B_m</td>\n",
       "      <td>A 46-year-old Black man presented with a left ...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is your diagnosis?</td>\n",
       "      <td>1</td>\n",
       "      <td>A 46-year-old man presented with a left should...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Basal cell carcinoma</td>\n",
       "      <td>b</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>Squamous cell carcinoma</td>\n",
       "      <td>female_augmented</td>\n",
       "      <td>augmented</td>\n",
       "      <td>...</td>\n",
       "      <td>What is your diagnosis?</td>\n",
       "      <td>41-50</td>\n",
       "      <td>https://jamanetwork.com/journals/jamaoncology/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Melanoma</td>\n",
       "      <td>28_GxE_a_B_m</td>\n",
       "      <td>A 46-year-old Black woman presented with a lef...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         clinical_question  test_lab  \\\n",
       "0  what is your diagnosis?         1   \n",
       "1  what is your diagnosis?         1   \n",
       "2  what is your diagnosis?         1   \n",
       "3  what is your diagnosis?         1   \n",
       "4  what is your diagnosis?         1   \n",
       "\n",
       "                                            question  gender_int  \\\n",
       "0  A 46-year-old man presented with a left should...           1   \n",
       "1  A 46-year-old man presented with a left should...          -1   \n",
       "2  A 46-year-old man presented with a left should...           0   \n",
       "3  A 46-year-old man presented with a left should...           1   \n",
       "4  A 46-year-old man presented with a left should...          -1   \n",
       "\n",
       "                    opb answer_idx_shuffled  \\\n",
       "0  Basal cell carcinoma                   b   \n",
       "1  Basal cell carcinoma                   b   \n",
       "2  Basal cell carcinoma                   b   \n",
       "3  Basal cell carcinoma                   b   \n",
       "4  Basal cell carcinoma                   b   \n",
       "\n",
       "                                         explanation             opa_shuffled  \\\n",
       "0  The biomarker SOX10 is highly sensitive and sp...  Squamous cell carcinoma   \n",
       "1  The biomarker SOX10 is highly sensitive and sp...  Squamous cell carcinoma   \n",
       "2  The biomarker SOX10 is highly sensitive and sp...  Squamous cell carcinoma   \n",
       "3  The biomarker SOX10 is highly sensitive and sp...  Squamous cell carcinoma   \n",
       "4  The biomarker SOX10 is highly sensitive and sp...  Squamous cell carcinoma   \n",
       "\n",
       "      version_gender version_binary  ...      normalized_question  age_group  \\\n",
       "0     male_augmented      augmented  ...  What is your diagnosis?      41-50   \n",
       "1   female_augmented      augmented  ...  What is your diagnosis?      41-50   \n",
       "2  neutral_augmented      augmented  ...  What is your diagnosis?      41-50   \n",
       "3     male_augmented      augmented  ...  What is your diagnosis?      41-50   \n",
       "4   female_augmented      augmented  ...  What is your diagnosis?      41-50   \n",
       "\n",
       "                                                link  test_image  \\\n",
       "0  https://jamanetwork.com/journals/jamaoncology/...           1   \n",
       "1  https://jamanetwork.com/journals/jamaoncology/...           1   \n",
       "2  https://jamanetwork.com/journals/jamaoncology/...           1   \n",
       "3  https://jamanetwork.com/journals/jamaoncology/...           1   \n",
       "4  https://jamanetwork.com/journals/jamaoncology/...           1   \n",
       "\n",
       "   woman_health figure       opc        key_id  \\\n",
       "0             0      1  Melanoma  28_GxE_a_W_m   \n",
       "1             0      1  Melanoma  28_GxE_a_W_m   \n",
       "2             0      1  Melanoma  28_GxE_a_W_m   \n",
       "3             0      1  Melanoma  28_GxE_a_B_m   \n",
       "4             0      1  Melanoma  28_GxE_a_B_m   \n",
       "\n",
       "                                                case   age  \n",
       "0  A 46-year-old White man presented with a left ...  46.0  \n",
       "1  A 46-year-old White woman presented with a lef...  46.0  \n",
       "2  A 46-year-old White patient presented with a l...  46.0  \n",
       "3  A 46-year-old Black man presented with a left ...  46.0  \n",
       "4  A 46-year-old Black woman presented with a lef...  46.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path=os.path.join(experiment_folder,'all_othercolumns.csv')\n",
    "df=pd.read_csv(df_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['clinical_question', 'test_lab', 'question', 'gender_int', 'opb',\n",
      "       'answer_idx_shuffled', 'explanation', 'opa_shuffled', 'version_gender',\n",
      "       'version_binary', 'diagnosis', 'pregnancy', 'answer_idx', 'case_id',\n",
      "       'test_other', 'opc_shuffled', 'opa', 'gender', 'version', 'opd',\n",
      "       'experiment', 'ethnicity', 'answer', 'augmented_gender', 'field',\n",
      "       'opb_shuffled', 'opd_shuffled', 'original_gender',\n",
      "       'version_gender_ethnicity', 'normalized_question', 'age_group', 'link',\n",
      "       'test_image', 'woman_health', 'figure', 'opc', 'key_id', 'case', 'age'],\n",
      "      dtype='object')\n",
      "Shape: (720, 39)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns: {df.columns}\")\n",
    "print(f\"Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['case_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.a. Explanation -> per unique case_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_dataframe_per_caseid(df, get_embedding, cosine_similarity, max_tokens=8192, experiment_name='exp1'):\n",
    "    # Create df_uniquecaseid with the first row for each unique case_id\n",
    "    df_uniquecaseid = df.groupby('case_id').first().reset_index()\n",
    "    \n",
    "    # Initialize new columns\n",
    "    new_columns = ['explanation_truncated', 'explanation_tokens', 'explanation_embedding']\n",
    "    response_columns = [col for col in df_uniquecaseid.columns if 'response' in col]\n",
    "    for col in response_columns:\n",
    "        new_columns.extend([f'{col}_truncated', f'{col}_tokens', f'{col}_embedding', f'{col}_embedding_sim'])\n",
    "    \n",
    "    for col in new_columns:\n",
    "        if col not in df_uniquecaseid.columns:\n",
    "            df_uniquecaseid[col] = None\n",
    "    \n",
    "    # Process df_uniquecaseid\n",
    "    total_rows = len(df_uniquecaseid)\n",
    "    for i, (index, row) in enumerate(df_uniquecaseid.iterrows(), 1):\n",
    "        # Create truncated versions if necessary\n",
    "        df_uniquecaseid.at[index, 'explanation_truncated'] = truncate_text(row['explanation'], max_tokens)\n",
    "        df_uniquecaseid.at[index, 'explanation_tokens'] = num_tokens_from_string(row['explanation'])\n",
    "        \n",
    "        # Calculate embedding for explanation\n",
    "        explanation_embedding = get_embedding(df_uniquecaseid.at[index, 'explanation_truncated'])\n",
    "        df_uniquecaseid.at[index, 'explanation_embedding'] = json.dumps(explanation_embedding)\n",
    "        \n",
    "        # Process response columns\n",
    "        for col in response_columns:\n",
    "            df_uniquecaseid.at[index, f'{col}_truncated'] = truncate_text(row[col], max_tokens)\n",
    "            df_uniquecaseid.at[index, f'{col}_tokens'] = num_tokens_from_string(row[col])\n",
    "            response_embedding = get_embedding(df_uniquecaseid.at[index, f'{col}_truncated'])\n",
    "            df_uniquecaseid.at[index, f'{col}_embedding'] = json.dumps(response_embedding)\n",
    "            df_uniquecaseid.at[index, f'{col}_embedding_sim'] = cosine_similarity(\n",
    "                explanation_embedding,\n",
    "                response_embedding\n",
    "            )\n",
    "        \n",
    "        # Print progress and save to CSV every 10%\n",
    "        if i % (total_rows // 10) == 0 or i == total_rows:\n",
    "            print(f\"Processed {i}/{total_rows} rows ({i/total_rows*100:.2f}%)\")\n",
    "            df_uniquecaseid.to_csv(f'progress/df_{experiment_name}_uniquecaseid_progress_row{i}.csv', index=False)\n",
    "\n",
    "    # Process the original dataframe\n",
    "    df_embed_uniquecaseid = df.copy()\n",
    "    \n",
    "    # Initialize new columns in df_embed_uniquecaseid\n",
    "    for col in new_columns:\n",
    "        if col not in df_embed_uniquecaseid.columns:\n",
    "            df_embed_uniquecaseid[col] = None\n",
    "    \n",
    "    # Map new columns from df_uniquecaseid to df_embed_uniquecaseid\n",
    "    columns_to_map = ['explanation_embedding'] + new_columns\n",
    "    for col in columns_to_map:\n",
    "        df_embed_uniquecaseid[col] = df_embed_uniquecaseid['case_id'].map(dict(zip(df_uniquecaseid['case_id'], df_uniquecaseid[col])))\n",
    "    \n",
    "    # Save the final dataframe\n",
    "    df_embed_uniquecaseid=df_embed_uniquecaseid[['case_id','explanation','explanation_truncated','explanation_tokens','explanation_embedding']]\n",
    "\n",
    "    df_embed_uniquecaseid.to_csv(f'{experiment_folder}/all_othercolumns_embed.csv', index=False)\n",
    "\n",
    "    \n",
    "    return df_embed_uniquecaseid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7/72 rows (9.72%)\n",
      "Processed 14/72 rows (19.44%)\n",
      "Processed 21/72 rows (29.17%)\n",
      "Processed 28/72 rows (38.89%)\n",
      "Processed 35/72 rows (48.61%)\n",
      "Processed 42/72 rows (58.33%)\n",
      "Processed 49/72 rows (68.06%)\n",
      "Processed 56/72 rows (77.78%)\n",
      "Processed 63/72 rows (87.50%)\n",
      "Processed 70/72 rows (97.22%)\n",
      "Processed 72/72 rows (100.00%)\n"
     ]
    }
   ],
   "source": [
    "df_embed_uniquecaseid = process_dataframe_per_caseid(df, get_embedding, cosine_similarity, experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>explanation</th>\n",
       "      <th>explanation_truncated</th>\n",
       "      <th>explanation_tokens</th>\n",
       "      <th>explanation_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>889</td>\n",
       "      <td>[-0.016631269827485085, 0.0067895445972681046,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>889</td>\n",
       "      <td>[-0.016631269827485085, 0.0067895445972681046,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>889</td>\n",
       "      <td>[-0.016631269827485085, 0.0067895445972681046,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>889</td>\n",
       "      <td>[-0.016631269827485085, 0.0067895445972681046,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>The biomarker SOX10 is highly sensitive and sp...</td>\n",
       "      <td>889</td>\n",
       "      <td>[-0.016631269827485085, 0.0067895445972681046,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>1184</td>\n",
       "      <td>Hypofractionated radiotherapy (ie, stereotacti...</td>\n",
       "      <td>Hypofractionated radiotherapy (ie, stereotacti...</td>\n",
       "      <td>593</td>\n",
       "      <td>[0.005163595546036959, 0.0015109177911654115, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1216</td>\n",
       "      <td>Repeated biopsy via thoracotomy revealed small...</td>\n",
       "      <td>Repeated biopsy via thoracotomy revealed small...</td>\n",
       "      <td>1112</td>\n",
       "      <td>[-0.006852500140666962, 0.023650746792554855, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>1233</td>\n",
       "      <td>Brain MRI revealed an enlarged, heterogeneousl...</td>\n",
       "      <td>Brain MRI revealed an enlarged, heterogeneousl...</td>\n",
       "      <td>947</td>\n",
       "      <td>[-0.03437063843011856, 0.0009665822726674378, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1281</td>\n",
       "      <td>The repeated CT scan demonstrated a persistent...</td>\n",
       "      <td>The repeated CT scan demonstrated a persistent...</td>\n",
       "      <td>764</td>\n",
       "      <td>[-0.03137677535414696, 0.02409636229276657, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1347</td>\n",
       "      <td>Repeated biopsy revealed epidermal infiltratio...</td>\n",
       "      <td>Repeated biopsy revealed epidermal infiltratio...</td>\n",
       "      <td>878</td>\n",
       "      <td>[-0.034156691282987595, 0.005574284121394157, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     case_id                                        explanation  \\\n",
       "0         28  The biomarker SOX10 is highly sensitive and sp...   \n",
       "1         28  The biomarker SOX10 is highly sensitive and sp...   \n",
       "2         28  The biomarker SOX10 is highly sensitive and sp...   \n",
       "3         28  The biomarker SOX10 is highly sensitive and sp...   \n",
       "4         28  The biomarker SOX10 is highly sensitive and sp...   \n",
       "..       ...                                                ...   \n",
       "715     1184  Hypofractionated radiotherapy (ie, stereotacti...   \n",
       "716     1216  Repeated biopsy via thoracotomy revealed small...   \n",
       "717     1233  Brain MRI revealed an enlarged, heterogeneousl...   \n",
       "718     1281  The repeated CT scan demonstrated a persistent...   \n",
       "719     1347  Repeated biopsy revealed epidermal infiltratio...   \n",
       "\n",
       "                                 explanation_truncated  explanation_tokens  \\\n",
       "0    The biomarker SOX10 is highly sensitive and sp...                 889   \n",
       "1    The biomarker SOX10 is highly sensitive and sp...                 889   \n",
       "2    The biomarker SOX10 is highly sensitive and sp...                 889   \n",
       "3    The biomarker SOX10 is highly sensitive and sp...                 889   \n",
       "4    The biomarker SOX10 is highly sensitive and sp...                 889   \n",
       "..                                                 ...                 ...   \n",
       "715  Hypofractionated radiotherapy (ie, stereotacti...                 593   \n",
       "716  Repeated biopsy via thoracotomy revealed small...                1112   \n",
       "717  Brain MRI revealed an enlarged, heterogeneousl...                 947   \n",
       "718  The repeated CT scan demonstrated a persistent...                 764   \n",
       "719  Repeated biopsy revealed epidermal infiltratio...                 878   \n",
       "\n",
       "                                 explanation_embedding  \n",
       "0    [-0.016631269827485085, 0.0067895445972681046,...  \n",
       "1    [-0.016631269827485085, 0.0067895445972681046,...  \n",
       "2    [-0.016631269827485085, 0.0067895445972681046,...  \n",
       "3    [-0.016631269827485085, 0.0067895445972681046,...  \n",
       "4    [-0.016631269827485085, 0.0067895445972681046,...  \n",
       "..                                                 ...  \n",
       "715  [0.005163595546036959, 0.0015109177911654115, ...  \n",
       "716  [-0.006852500140666962, 0.023650746792554855, ...  \n",
       "717  [-0.03437063843011856, 0.0009665822726674378, ...  \n",
       "718  [-0.03137677535414696, 0.02409636229276657, -0...  \n",
       "719  [-0.034156691282987595, 0.005574284121394157, ...  \n",
       "\n",
       "[720 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed_uniquecaseid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in the dataframe: 0\n",
      "Number of unique case_id: 72\n",
      "Columns: Index(['case_id', 'explanation', 'explanation_truncated', 'explanation_tokens',\n",
      "       'explanation_embedding'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# === Analysis\n",
    "\n",
    "# --- 2/ Check the NA values\n",
    "print(f\"NaN values in the dataframe: {df_embed_uniquecaseid.isna().sum().sum()}\")\n",
    "\n",
    "# ---3/ Check the number of unique case_id\n",
    "print(f\"Number of unique case_id: {df_embed_uniquecaseid['case_id'].nunique()}\")\n",
    "\n",
    "# ---4/ Check the number of columns\n",
    "print(f\"Columns: {df_embed_uniquecaseid.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a.b. LLM output --> Per llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/ Loading and preprocessing the data\n",
      "Loaded and preprocessed: llm_gpt4o.csv\n",
      "Loaded and preprocessed: llm_gpt4omini.csv\n",
      "Loaded and preprocessed: llm_gpt3.csv\n",
      "Loaded and preprocessed: llm_gpt4turbo.csv\n",
      "2/ Processing DataFrames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: llm_gpt4o.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 4/4 [07:51<00:00, 117.79s/it]\n",
      "Processing files:  25%|██▌       | 1/4 [07:54<23:42, 474.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/genderxethnicity/cleaned_results/llm_gpt4o_embed.csv\n",
      "\n",
      "Processing: llm_gpt4omini.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 4/4 [08:01<00:00, 120.42s/it]\n",
      "Processing files:  50%|█████     | 2/4 [15:58<16:00, 480.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/genderxethnicity/cleaned_results/llm_gpt4omini_embed.csv\n",
      "\n",
      "Processing: llm_gpt3.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 3/3 [05:54<00:00, 118.20s/it]\n",
      "Processing files:  75%|███████▌  | 3/4 [21:55<07:04, 424.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/genderxethnicity/cleaned_results/llm_gpt3_embed.csv\n",
      "\n",
      "Processing: llm_gpt4turbo.csv\n",
      "2a/ Adding explanation embeddings\n",
      "2b/ Calculating embeddings and similarities for responses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████| 3/3 [06:21<00:00, 127.08s/it]\n",
      "Processing files: 100%|██████████| 4/4 [28:19<00:00, 424.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to: /Users/kenzabenkirane/Desktop/GitHub/24ucl_thesis/bias_llm_clinical_challenge/results/experiment1/genderxethnicity/cleaned_results/llm_gpt4turbo_embed.csv\n",
      "3/ Done processing all DataFrames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_llm_csvs_GxE(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string, max_tokens=8192):\n",
    "    print(\"1/ Loading and preprocessing the data\")\n",
    "    dfs = []\n",
    "    file_paths = []\n",
    "    for file in os.listdir(experiment_folder):\n",
    "        if file.startswith('llm_') and file.endswith('.csv'):\n",
    "            file_path = os.path.join(experiment_folder, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Preprocess: Convert all 'response' columns to string type and handle NaN values\n",
    "            response_columns = [col for col in df.columns if 'response' in col]\n",
    "            for col in response_columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "            df = df.fillna('')\n",
    "            \n",
    "            dfs.append(df)\n",
    "            file_paths.append(file_path)\n",
    "            print(f\"Loaded and preprocessed: {file}\")\n",
    "    \n",
    "    print(\"2/ Processing DataFrames\")\n",
    "    for df, file_path in tqdm(zip(dfs, file_paths), total=len(dfs), desc=\"Processing files\"):\n",
    "        print(f\"\\nProcessing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # 2a/ Get the embedding of explanation from df_embed_uniquecaseid\n",
    "        print(\"2a/ Adding explanation embeddings\")\n",
    "        # Create a dictionary mapping case_id to embedding, keeping only the first occurrence of each case_id\n",
    "        embedding_dict = df_embed_uniquecaseid.groupby('case_id')['explanation_embedding'].first().to_dict()\n",
    "        df['explanation_embedding'] = df['case_id'].map(embedding_dict)\n",
    "        \n",
    "        # 2b/ Calculate the embedding of each response and the cosine similarity with the explanation\n",
    "        print(\"2b/ Calculating embeddings and similarities for responses\")\n",
    "        columns_to_evaluate = [col for col in df.columns if 'response' in col]\n",
    "        for col in tqdm(columns_to_evaluate, desc=\"Processing columns\"):\n",
    "            df[f'{col}_truncated'] = df[col].apply(lambda x: truncate_text(x, max_tokens))\n",
    "            df[f'{col}_tokens'] = df[col].apply(num_tokens_from_string)\n",
    "            df[f'{col}_embedding'] = df[f'{col}_truncated'].apply(get_embedding).apply(json.dumps)\n",
    "            df[f'{col}_embedding_sim'] = df.apply(lambda x: cosine_similarity(\n",
    "                json.loads(x['explanation_embedding']), \n",
    "                json.loads(x[f'{col}_embedding'])\n",
    "            ), axis=1)\n",
    "        \n",
    "        # 2c/ Save the DataFrame\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_path = os.path.join(os.path.dirname(file_path), f\"{base_name}_embed.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved processed data to: {output_path}\")\n",
    "\n",
    "    print(\"3/ Done processing all DataFrames\")\n",
    "\n",
    "# Usage\n",
    "process_llm_csvs_GxE(get_embedding, cosine_similarity, truncate_text, num_tokens_from_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
